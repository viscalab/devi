---
title: "Untitled"
format: html
editor: visual
---


```{r}
library(tidyverse)
library(rlang)
library(broom)

list.files("R", full.names = TRUE) |> walk(source)
```

## Reading the data

```{r}
dat <- read.csv("data/my_data.csv") |> 
  filter(participant == "s01")
```

## Fit a glm to the data

```{r}
fit <- fit_glm(dat, resp, x)
```

```{r}
ggplot() +
  geom_point(data = fit$prop,
             aes(x = x, y = prop)) +
  geom_line(data = fit$psy, 
            aes(x = x, y = prop)) +
  geom_segment(data = fit$param, 
               aes(x = bias, xend = bias, 
                   y = 0, yend = .5))
```

## Goodness of fit

To assess whether the proposed model is a good fit of the data we can look at the residual deviance

```{r}
fit$deviance |> 
  filter(type == "residual")
```

The model is good. 


## Null model

To assess whether a model that assumes that the responses do not depend on the predictor (flat psychometric function) we can look at the null deviance

```{r}
fit$deviance |> 
  filter(type == "null")
```

The null model (flat psychometric function) is not a good fit of the data. 


## Goodness of fit. Looking into the details

Let's first calculate the summarise of number of "Yes" and "No" responses

```{r}
prop <- dat |> 
  group_by(x) |> 
  summarise(k = sum(resp), n = n(), prop = k / n)
```


The proposed model is

$$f(k_1, \cdots, k_8;\beta_0, \beta_1) = \prod_{i=1}^{8} \binom{120}{k_i} \Psi(x_i;\beta_0, \beta_1)^{k_i} (1-\Psi(x_i;\beta_0, \beta_1))^{120-k_i}$$

and the log likelihood dropping the binomial coefficient because does not depends on the parameters is

$$l(\beta_0, \beta_1) = \sum_{i=1}^{8} k_i  \log \Psi(x_i;\beta_0, \beta_1) + (120-k_i) \log (1-\Psi(x_i;\beta_0, \beta_1))$$

We want to fit a logistic function

```{r}
logistic_fun <- function(x, p) {
  1 / (1 + exp(-p[1] - p[2] * x))
}
```


There are several ways to create the log likelihood function, but we will use a function factory, that is a function, that allows creating another function. Here we input the data and create the negative log likelihood. We created the negative log likelihood instead of the log likelihood because the function for optimization `optim` search for a minimum. 

```{r}
create_neg_log_lik_fun <- function(.data) {
  function(p) {
    psi <- logistic_fun(.data$x, p)
    -sum(.data$k * log(psi) + (.data$n - .data$k) * log(1 - psi))
  }
}

neg_log_lik_fun <- create_neg_log_lik_fun(prop)

```

We already have the function, so let's search for the parameters that mimize it


```{r}
fit_hand <- optim(c(1, .01), neg_log_lik_fun)

fit_hand
```
The parameters, of course, are the same that those obtained using `glm`:

```{r}
fit$param
```
The likelihood of the proposed model is

```{r}
-fit_hand$value
```


Now, let's do the same for the saturated model, the model that uses one parameter for each data point

```{r}
create_neg_log_lik_saturated_fun <- function(.data) {
  function(p) {
    -sum(.data$k * log(p) + (.data$n - .data$k) * log(1 - p))
  }
}

neg_log_lik_saturated_fun <- create_neg_log_lik_saturated_fun(prop)

fit_hand_saturated <- optim(c(.1, .1, .5, .5, .8, .9, .9, .9),
                            neg_log_lik_saturated_fun)

fit_hand_saturated
```

The parameters coincide with the proportions

```{r}
prop
```

as we know that the maximum likelihood estimator of the p parameters of a binomial distribution with known n is k / n. 

The likelihood of the saturate model is

```{r}
-fit_hand_saturated$value
```

that, of course, is larger than the likelihood of proposed model. 


The log likelihood ratio of the saturated model relative to the proposed model is

$$\log{\frac{\Lambda_s}{\Lambda_p}}$$
This is large if the saturated model is much better than the proposed model. 
Under the proposed model 2 times this quatity (deviance) is distributed chi square with degrees of freedom equal to the difference in the number of parameters. 

```{r}
residual_deviance_hand <- 2 * (-fit_hand_saturated$value - (-fit_hand$value))

residual_deviance_hand
```

```{r}
pchisq(q = residual_deviance_hand, df = 6, lower.tail = FALSE)
```

The proposed model is ok.


To assess the null model:

```{r}
create_neg_log_lik_null_fun <- function(.data) {
  n_predictor <- length(.data$k)
  function(p) {
    -sum(.data$k * log(rep(p, n_predictor)) + 
           (.data$n - .data$k) * log(1 - rep(p, n_predictor)))
  }
}

neg_log_lik_null_fun <- create_neg_log_lik_null_fun(prop)

fit_hand_null <- optim(c(.5), neg_log_lik_null_fun)

fit_hand_null
```

```{r}
null_deviance_hand <- 2 * (-fit_hand_saturated$value - (-fit_hand_null$value))

null_deviance_hand
```

```{r}
pchisq(null_deviance_hand, 7, lower.tail = FALSE)
```

